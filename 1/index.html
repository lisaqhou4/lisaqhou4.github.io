<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Overview</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            padding: 0;
        }
        h1, h2 {
            color: #333;
        }
        .section {
            margin-bottom: 30px;
        }
        .image-container {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
        }
        .image-container img {
            max-width: 200px;
            height: auto;
        }
    </style>
</head>
<body>
    <header>
        <h1>Project Overview</h1>
    </header>

    <section class="section" id="overview">
        <h2>Brief Overview of the Project</h2>
        <p>The objective of this assignment is to utilize image processing techniques to reconstruct a color image from digitized Prokudin-Gorskii glass plate images while minimizing visual artifacts. 
            Each glass plate image contains three separate exposures corresponding to the blue, green, and red channels. To create a single RGB image, the three color channel images are separated, stacked, 
            and then aligned accurately. All image processing functions were implemented from scratch, and several methods were explored to enhance the quality of the final color image. </p>
            <div>
                <img src="./media/cathedral.jpg" alt="Example of the Prokudin-Gorskii glass plate images", height="500">
                <figcaption>Example of the Prokudin-Gorskii glass plate images</figcaption>
                
            </div>
        </section>

    <section class="section" id="approach">
        <h2> Basic Approach</h2>
        <p>The initial approach involves dividing the glass plate image along the y-axis into three separate color channels: blue, green, and red. The blue channel is considered the reference, and the goal is to align the green and red channels to it. To achieve this, the Normalized Cross-Correlation (NCC) score is employed to compute the optimal (x, y) translation that minimizes the misalignment between channels.  To calculate the NCC score, each image is first converted to zero-mean by subtracting its mean. Then, the Frobenius norm is computed to normalize these images to unit length. The NCC score is the dot product of the normalized images, where a higher score indicates better alignment.

            The pixel values at the edges of the image are often distorted or contain irrelevant data; therefore, a border of 15 pixels is ignored during the NCC score calculation to avoid any influence from them.
            
            For smaller images (300x300), an exhaustive search method is used to find the optimal alignment. This method searches over a window size of 20 pixels around the initial alignment and calculates the NCC score for each potential translation. This approach takes around ~40s to complete for small images.  </p>
        <div class="image-container"></div>
            <div>
                <img src="./media/cathedral_aligned.jpg" alt="Example of the exhaustive search result", height="500">
                <figcaption>  Aligned Color image of Cathedral.jpg</figcaption>
                <p>Offset: (x, y)</p>
            </div>
        </div>
    </section>

    <section class="section" id="approach">
        <h2> Pyramid Alignment Speed-up</h2>
        <p> While the basic exhaustive search approach is effective for small images, it becomes impractical for larger images (e.g., 3000x3000 pixels), where the exhaustive method can take approximately 6 minutes. To address this, a pyramid search process is implemented to accelerate the alignment.

            The pyramid search approach starts by aligning the image at a coarse level with a reduced resolution, using a larger search window. It then sequentially upsamples the image resolution while decreasing the search window size. At each level of the pyramid, the optimal translation is calculated and accumulated to refine the alignment further. This hierarchical method allows for a more efficient search and significantly reduces the computational time to around 1 minute for larger images. </p>
        
            For the pyramid search apporach used, a total of 4 levels are used with a initalized window size of 5 pixels (finest level) and a window size increment of 5 for each level. The pyramid search approach has significantly improved the alignment process for larger images. </p>
            <div class="image-container"></div>
            <div>
                <img src="/media/cathedral.jpg" alt="Example for the exhaustive approch">
                <figcaption>  Aligned Color image of Cathedral.jpg </figcaption>
                <p>Offset: (x, y)</p>
            </div>
        </div>
    </section>

    <section class="section" id="approach">
        <h2> Automatic Cropping</h2>
        <p> In some cases, images may have white or black borders that adversely affect the alignment process because these extreme pixel values can skew the NCC calculation, leading to poor alignment. To handle such cases, an automatic cropping function is introduced.

            The cropping function calculates average pixel values of the top, bottom, left, and right borders of the image, and determines the crop values based on the threshold of the average pixel values (where average values larger then 0.9 and less than 0.15 indicates white and black borders respectively). Based on a predefined threshold, these border regions are automatically cropped from the three channels before alignment, eliminating their influence on the NCC calculation. This preprocessing step greatly improves alignment results, especially for images with large or irregular borders. </p> 
        </p>
        <div class="image-container" style="display: flex; gap: 20px; align-items: center;">

            <!-- Image 1 with Caption -->
            <div style="text-align: center;">
                <img src="./media/cathedral.jpg" alt="Example of less aligned image" style="max-width: 300px; height: auto; border: 1px solid #ddd; border-radius: 4px;">
                <figcaption>Without Automatic Cropping</figcaption>
                <p>Offset: (x, y)</p>
            </div>
    
            <!-- Image 2 with Caption -->
            <div style="text-align: center;">
                <img src="./media/cathedral.jpg" alt="Example of improved image" style="max-width: 300px; height: auto; border: 1px solid #ddd; border-radius: 4px;">
                <figcaption>With Automatic Cropping</figcaption>
                <p>Offset: (x, y)</p>
            </div>
    
        </div>
    </section>

    <section class="section" id="approach">
        <h2> Sobel Edge Detector </h2>
        <p> Using the raw RGB color channel pixel values to calculate the NCC score for alignment can fail when the channels are imbalanced in terms of light or information captured. For example, in the Emir's image, his blue jacket appears prominently in the blue channel but is much less visible in the green and red channels, leading to misalignment when relying on pixel values alone. To address this, I implemented a Sobel Edge Detector to extract edge features from the image and use them for image alignment. The Sobel Edge Detector is a popular image processing technique used to highlight edges within an image by calculating the gradient magnitude of pixel intensities. It works by applying two convolutional kernels (one for detecting changes in the x-direction and another in the y-direction) to approximate the image's first derivative. This results in an image where edges are highlighted, which is useful for edge detection and feature extraction.

            By aligning the images based on their edge features rather than raw pixel values, this approach provides a more consistent alignment for images with uneven color distribution. 
        </p> 

        <div class="image-container"></div>
            <div>
                <img src="/media/cathedral.jpg" alt="Example of less aligned image">
            </div>

            <div></div>
                <img src="/media/cathedral.jpg" alt="Example of improved image">
            </div>
        </div>
    </section>

    <section class="section" id="results">
        <h2>Results on Example Images</h2>
        <p>Here, you should display the results of your algorithm on all example images. List the offsets you calculated. Only use compressed images (e.g., jpg, png, gif) for display purposes.</p>
        <div class="image-container">
            <!-- Example of adding an image -->
            <div>
                <img src="./media/example1.jpg" alt="Result Image 1">
                <p>Offset: (x, y)</p>
            </div>
            <div>
                <img src="./media/example2.jpg" alt="Result Image 2">
                <p>Offset: (x, y)</p>
            </div>
            <!-- Add more images as needed -->
        </div>
    </section>

    <section class="section" id="custom-results">
        <h2>Results on Selected Images from the Prokudin-Gorskii Collection</h2>
        <p>Display the results of your algorithm on a few images from the Prokudin-Gorskii collection that you chose to work with.</p>
        <div class="image-container">
            <!-- Example of adding an image -->
            <div>
                <img src="./media/custom1.jpg" alt="Custom Image 1">
                <p>Offset: (x, y)</p>
            </div>
            <!-- Add more images as needed -->
        </div>
    </section>

    <section class="section" id="failures">
        <h2>Failed Alignments</h2>
        <p>If your algorithm failed to align any images, provide an explanation of why it happened and possible reasons for the failure.</p>
    </section>


    
</body>
</html>
